# Практика 2: Исследование атак на модели ИИ. Fast Gradient Sign Method (FGSM)
Выполнил студент группы ББМО-02-23 Макаров М.М.

### (По ошибке была выполнена изначально практика ПРЗ_1 из системы СДО, отчёт по ней был загружен в систему 3го октября, ссылку на таблицу и всё остальное я узнал несколько позже, решил сразу сделать и 1 и 2ую практики)
### Прошу зачесть в т.ч. и первую практику

Ссылка на notebook в Google colab: https://colab.research.google.com/drive/1wtKQze9_xyRSiP-410A3BLxXAcC8RZwr?usp=sharing

## Цель задания:

Познакомиться с одной из популярных атак на системы машинного обучения — атакой Fast Gradient
Sign Method (FGSM). Задача — научиться использовать FGSM для создания противоречивых (adversarial)
примеров, которые могут ввести обученную модель в заблуждение.

Задачи:

  1. Загрузить ранее обученную модель на датасете MNIST.
  2. Изучить теоретические основы FGSM.
  3. Реализовать атаку FGSM и сгенерировать противоречивые примеры.
  4. Оценить точность модели на противоречивых примерах и сравнить с результатами на обычных данных.
